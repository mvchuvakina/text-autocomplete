{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652dc485",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, AutoTokenizer, AutoModelForCausalLM\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Используем устройство:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b1b11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.data_utils import load_and_prepare_data\n",
    "from src.next_token_dataset import TextDataset\n",
    "from src.lstm_model import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39133005",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df, tokenizer, tokens = load_and_prepare_data(data_dir=\"data\", max_len=20, min_len=7, use_sample=True)\n",
    "\n",
    "print(\"Пример первых строк датасета:\")\n",
    "print(df.head())\n",
    "print(\"Пример токенов:\")\n",
    "print(tokens['input_ids'][:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc1719",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_examples(tokens_ids):\n",
    "    X_list, Y_list = [], []\n",
    "    for token in tokens_ids:\n",
    "        X = token[:-1]\n",
    "        Y = token[1:]\n",
    "        X_list.append(torch.tensor(X))\n",
    "        Y_list.append(torch.tensor(Y))\n",
    "    return X_list, Y_list\n",
    "\n",
    "token_ids = tokens['input_ids'].tolist()\n",
    "train_ids, temp_ids = train_test_split(token_ids, test_size=0.2, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train, Y_train = create_examples(train_ids)\n",
    "\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функция генерации последовательности\n",
    "def generate_sequence(model, start_seq, max_len=20):\n",
    "    model.eval()\n",
    "    generated = start_seq.tolist()\n",
    "    input_seq = start_seq.unsqueeze(0).to(device)\n",
    "    hidden = None\n",
    "    for _ in range(max_len):\n",
    "        logits, hidden = model(input_seq, hidden)\n",
    "        next_token = torch.argmax(logits[:, -1, :], dim=-1)\n",
    "        generated.append(next_token.item())\n",
    "        input_seq = torch.cat([input_seq, next_token.unsqueeze(0)], dim=1)\n",
    "    return generated\n",
    "\n",
    "# Тренировка одной эпохи\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, Y in tqdm(loader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(X)\n",
    "        loss = criterion(logits.view(-1, vocab_size), Y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Оценка ROUGE\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            for i in range(X.size(0)):\n",
    "                seq_input = X[i][:int(0.75*X.size(1))]\n",
    "                target_seq = Y[i][int(0.75*Y.size(1)):]\n",
    "                pred_tokens = generate_sequence(model, seq_input, max_len=len(target_seq))\n",
    "                pred_text = tokenizer.decode(pred_tokens[-len(target_seq):])\n",
    "                target_text = tokenizer.decode(target_seq.tolist())\n",
    "                score = scorer.score(pred_text, target_text)['rougeL'].fmeasure\n",
    "                scores.append(score)\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "X_val, Y_val = create_examples(val_ids)\n",
    "X_test, Y_test = create_examples(test_ids)\n",
    "\n",
    "train_dataset = TextDataset(X_train, Y_train)\n",
    "val_dataset = TextDataset(X_val, Y_val)\n",
    "test_dataset = TextDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Размеры выборок:\", len(train_dataset), len(val_dataset), len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7caf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = LSTMModel(vocab_size, embed_dim=128, hidden_dim=128, num_layers=1).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0bcc5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Этап 3: Тренировка LSTM\n",
    "\n",
    "for epoch in range(2):\n",
    "    loss = train_epoch(model, train_loader)\n",
    "    rouge_score = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, ROUGE-L={rouge_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588162b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Этап 4: Предобученный трансформер\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model_gpt = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(device)\n",
    "\n",
    "def generate_gpt2(text, max_new_tokens=20):\n",
    "    inputs = tokenizer_gpt(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_gpt.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    return tokenizer_gpt.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Проверка на первых 50 примерах\n",
    "scores = []\n",
    "for text in df['text'][:50]:\n",
    "    input_text = ' '.join(text.split()[:int(len(text.split())*0.75)])\n",
    "    target_text = ' '.join(text.split()[int(len(text.split())*0.75):])\n",
    "    pred_text = generate_gpt2(input_text)\n",
    "    score = scorer.score(pred_text, target_text)['rougeL'].fmeasure\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Average ROUGE-L for GPT2:\", sum(scores)/len(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877bbb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Этап 5: Выводы\n",
    "print(\"Сравнение моделей:\")\n",
    "print(\"- LSTM: ROUGE-L на валидации (после 2 эпох):\", rouge_score)\n",
    "print(\"- DistilGPT2: ROUGE-L на первых 50 примерах:\", sum(scores)/len(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ede56",
   "metadata": {},
   "source": [
    "**Сравнение моделей:**\n",
    "\n",
    "LSTM:\n",
    "\n",
    "- Быстрее обучение\n",
    "- Меньше требований к памяти\n",
    "- Стабильная сходимость\n",
    "- Transformer пострадал от сокращения:\n",
    "\n",
    "\n",
    "Transformer:\n",
    "- Недостаточно данных\n",
    "- Низкое качество\n",
    "- Требует полного датасета для раскрытия потенциала\n",
    "- Ключевые выводы\n",
    "\n",
    "LSTM показала лучшие результаты на сокращенных данных:\n",
    "\n",
    "Высокое качество (ROUGE-L: 0.346 vs 0.045) Эффективность на малых данных - главное преимущество Быстрая сходимость - хорошие результаты после 2 эпох Устойчивость к ограничениям ресурсов"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
